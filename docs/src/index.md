# NonlinearBandits.jl

[NonlinearBandits.jl](https://github.com/dfcorbin/NonlinearBandits.jl) provides an easy to use
framework for implementing contextual multi-armed bandit policies, and testing them with
synthetic environments. Pre-implemented policies can be found in the [Bandits API](@ref)
which may be useful to compare with.

I recommend reading through the Tutorials (particularly the [Bandits Tutorial](@ref))
as a good starting point.

```@index
```