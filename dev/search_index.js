var documenterSearchIndex = {"docs":
[{"location":"","page":"API","title":"API","text":"CurrentModule = NonlinearBandits","category":"page"},{"location":"#NonlinearBandits","page":"API","title":"NonlinearBandits","text":"","category":"section"},{"location":"","page":"API","title":"API","text":"Documentation for NonlinearBandits.","category":"page"},{"location":"","page":"API","title":"API","text":"","category":"page"},{"location":"","page":"API","title":"API","text":"Modules = [NonlinearBandits]","category":"page"},{"location":"#NonlinearBandits.AbstractBayesianLM","page":"API","title":"NonlinearBandits.AbstractBayesianLM","text":"Abstract type for models using a Gaussian/normal-inverse-gamma conjugate prior.\n\n\n\n\n\n","category":"type"},{"location":"#NonlinearBandits.BayesLM-Tuple{Int64}","page":"API","title":"NonlinearBandits.BayesLM","text":"BayesLM(d::Int; <keyword arguments>)\n\nConstruct a Bayesian linear model.\n\nArguments\n\nλ::Float64=1.0: Prior scaling.\nshape0::Float64=1e-3: Inverse-gamma prior shape hyperparameter.\nscale0::Float64=1e-3: Inverse-gamma prior scale hyperparameter.\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.BayesPM-Tuple{Vector{Index}, Matrix{Float64}}","page":"API","title":"NonlinearBandits.BayesPM","text":"BayesPM(basis::Vector{Index}, limits::Matrix{Float64}; λ::Float64=1.0,\n        shape0::Float64=1e-3, scale0::Float64=1e-3)\n\nConstruct a Bayesian linear model on polynomial features.\n\nArguments\n\nbasis::Vector{Index}: Vector of monomial indices.\nlimits::Matrix{Float64}: Matrix with two columns defining the lower/upper limits of the space.\nλ::Float64=1.0: Prior covariance scale factor.\nshape0::Float64=1e-3: Inverse-gamma prior shape hyperparameter.\nscale0::Float64=1e=3: Inverse-gamma prior scale hyperparameter.\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.Index","page":"API","title":"NonlinearBandits.Index","text":"Index(dim::Vector{Int64}, deg::Vector{Int64})\n\nMultivariate monomial index.\n\nThe monomial x[1] * x[3]^2can be encoded usingdim = [1, 3],deg = [1, 2]`\n\n\n\n\n\n","category":"type"},{"location":"#NonlinearBandits.Partition-Tuple{Matrix{Float64}}","page":"API","title":"NonlinearBandits.Partition","text":"Partition(limits::Matrix{Float64})\n\nConstruct an object capable of storing a hyperrectangular partition.\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.PartitionedBayesPM-Tuple{Partition, Vector{Int64}}","page":"API","title":"NonlinearBandits.PartitionedBayesPM","text":"PartitionedBayesPM(P::Partition, Js::Vector{Int64}; <keyword arguments>)\n\nContruct a partitioned polynomial model.\n\nArguments\n\nP::Partition: A partition of the space.\nλ::Float64=1.0: Prior scaling.\nshape0::Float64=1e-3: Inverse-gamma prior shape hyperparameter.\nscale0::Float64=1e-3: Inverse-gamma prior scale hyperparameter.\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.auto_partitioned_bayes_pm-Tuple{AbstractMatrix, AbstractMatrix, Matrix{Float64}}","page":"API","title":"NonlinearBandits.auto_partitioned_bayes_pm","text":"auto_partitioned_bayes_pm(X::AbstractMatrix, y::AbstractMatrix, limits::Matrix{Float64};\n                          <keyword arguments>)\n\nPerform a 1-step look ahead greedy search for a partitioned polynomial model.\n\nKeyword Arguments\n\nJmax::Int64=3: The maximum degree of any polynomial model.\nPmax::Int64=500: The maximum number of features in a particular regions.\nKmax::Int64=200: The maximum number of regions\nλ::Float64=1.0: Prior scaling.\nshape0::Float64=1e-3: Inverse-gamma prior shape hyperparameter.\nscale0::Float64=1e-3: Inverse-gamma prior scale hyperparameter.\nratio::Float64=1.0: Polynomial degrees are reduced until size(X, 2) < ratio * length(tpbasis(d, J)).\ntol::Float64=1e-4: The required increase in the model evidence to accept a split.\nverbose::Bool=true: Print details of the partition search.\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.expand-Tuple{AbstractMatrix, Vector{Index}, Matrix{Float64}}","page":"API","title":"NonlinearBandits.expand","text":"expand(X::AbstractMatrix, basis::Vector{Index}, limits::Matrix{Float64};\n       J::Union{Nothing,Int64}=nothing)\n\nExpand the columns of X into a rescaled legendre polynomial basis.\n\nArguments\n\nX::AbstractMatrix: Matrix with observations stored as columns.\nbasis::Vector{Index}: Vector of monomial indices.\nlimits::Matrix{Float64}: Matrix with two columns defining the lower/upper limits of the space.\nJ::Union{Nothing, Int64}=nothing: The maximum degree of the basis. Inferred if not specified.\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.fit!-Tuple{Any, AbstractMatrix, AbstractMatrix}","page":"API","title":"NonlinearBandits.fit!","text":"fit!(model, X::AbstractMatrix, y::AbstractMatrix)\n\nUpdate the parameters of model.\n\nArguments\n\nX::AbstractMatrix: A matrix with observations stored as columns.\ny::AbstractMatrix: A matrix with 1 row of response variables. \n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.lasso_selection-Tuple{AbstractMatrix, AbstractMatrix, Int64, Bool}","page":"API","title":"NonlinearBandits.lasso_selection","text":"lasso_selection(X::AbstractMatrix, y::AbstractMatrix, Pmax::Int64, intercept::Bool)\n\nChoose the first Pmax features introduced by a LASSO solution path.\n\nArguments\n\nX::AbstractMatrix: A matrix with observations stored as columns.\ny::AbstractMatrix: A matrix with 1 row of response variables. \nPmax::Int64: The maximum number of predictors.\nintercept::Bool: true if the first row of X are the intercept features\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.split!-Tuple{Partition, Int64, Int64}","page":"API","title":"NonlinearBandits.split!","text":"split!(P::Partition, k::Int64, d::Int64)\n\nSplit the k'th subregion of P into equal halves in dimension d.\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.std-Tuple{AbstractBayesianLM}","page":"API","title":"NonlinearBandits.std","text":"std(model)\n\nComputed the posterior expected standard deviation from the model.\n\n\n\n\n\n","category":"method"},{"location":"#NonlinearBandits.tpbasis-Tuple{Int64, Int64}","page":"API","title":"NonlinearBandits.tpbasis","text":"tpbasis(d::Int64, J::Int64)\n\nConstruct the d-dimensional truncated tensor-product basis.\n\nAll index terms have a degree ≤ J.\n\nSee also Index\n\n\n\n\n\n","category":"method"},{"location":"regression_tutorial/#Model-API","page":"Models","title":"Model API","text":"","category":"section"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"This tutorial outlines some of the available models in NonlinearBandits.jl. First we generate some synthetic data to work with.","category":"page"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"using NonlinearBandits, Plots\n\nd, n = 1, 500\nf(x) = 10 * sin(5^(2 * x[1]) * x[1])\nX, y = NonlinearBandits.gaussian_data(d, n, f)\ndata_plt = plot(X[1, :], y[1, :], label=nothing, alpha=0.3, legend=:topleft, st=:scatter)","category":"page"},{"location":"regression_tutorial/#Bayesian-Linear-Model","page":"Models","title":"Bayesian Linear Model","text":"","category":"section"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"A simple Bayesian linear model is implemented by the BayesLM type.","category":"page"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"lm = BayesLM(d)\nfit!(lm, X, y)\n\nxplt = 0:0.01:1\nxplt = reshape(xplt, (d, :))\nyplt = lm(xplt) # Call model object to make predictions\nplot(data_plt, xplt[1, :], yplt[1, :], label=\"Linear model\")","category":"page"},{"location":"regression_tutorial/#Bayesian-Polynomial-Model","page":"Models","title":"Bayesian Polynomial Model","text":"","category":"section"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"Using a BayesPM object, we can create a wrapper for the BayesLM class, which first applies a polynomial expansion to the features.","category":"page"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"limits = repeat([0.0 1.0], d, 1) # Define hyperrectangular limits of the feature space\nbasis = tpbasis(d, 3) # Use the degree-3 truncated polynomial tensor-product basis\npm = BayesPM(basis, limits)\nfit!(pm, X, y)\nyplt = pm(xplt) \nplot(data_plt, xplt[1, :], yplt[1, :], label=\"Polynoimal model\")","category":"page"},{"location":"regression_tutorial/#Partitioned-Bayesian-Polynomial-Model","page":"Models","title":"Partitioned Bayesian Polynomial Model","text":"","category":"section"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"A more complex polynomial can be constructed by assigning low-degree polynomials to disjoint regions of a partition. Suppose we wanted to partition our 1-dimensional feature space into two disjoint regions, the partitioning api works as follows.","category":"page"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"P = Partition(limits)\nsplit!(P, 1, 1) # Split subregion 1 in dimension 1.\nprintln(\"Region 1: \", P.regions[1])\nprintln(\"Region 2: \", P.regions[2])","category":"page"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"To construct the partitioned polynomial, given P:","category":"page"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"ppm = PartitionedBayesPM(P, [3, 2])\nfit!(ppm, X, y)\nyplt = ppm(xplt)\nplot(data_plt, xplt[1, :], yplt[1, :], label=\"Partitioned model\")","category":"page"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"Often a good choice of partition is not easy to construct by hand. In this case, auto_partitioned_bayes_pm will perform a 1-step look ahead greedy search to build the partition automatically. The degrees for each polnomial are chosen automatically.","category":"page"},{"location":"regression_tutorial/","page":"Models","title":"Models","text":"auto_ppm = auto_partitioned_bayes_pm(X, y, limits)\nyplt = auto_ppm(xplt)\nplot(data_plt, xplt[1, :], yplt[1, :], label=\"Partitioned model\")","category":"page"}]
}
